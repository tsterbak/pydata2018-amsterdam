{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# “Why Should I Trust You?” - Debugging black-box text classifiers\n",
    "### Tobias Sterbak / PyData Amsterdam / 27-08-18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6bfcabb1-4fb7-4e73-9967-52ab2fb2e179"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- The problem of interpreting black-box classfier often used in text\n",
    "  classification. When alorithms make predictions about medical treatments\n",
    "  or if you just want to know whats going on before you release a model to a\n",
    "  production enviroment. => you (and your users) want to gain trust in the model!\n",
    "- What is a black-box classifier? Even a linear model can be hard to interpret [EXAMPLE]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# When do you trust a model?\n",
    "<p> </p>\n",
    "<p> </p>\n",
    "<p> </p>\n",
    "<center><img src=\"img/trust_robot.gif\" alt=\"trust\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- metrics are not enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "doesn't reveal dataset leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a validation set is not enougth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    " to estimate performance on production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a black-box model?\n",
    "\n",
    "<center>![blackbox](img/blackbox.jpg)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A system where the internal workings are completly hidden from you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Examples:_\n",
    "- Deep neural network\n",
    "- even a linear model with bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The LIME algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Example and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How to make it fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5af75f11-dd17-47d2-8bb5-c06a7121ed1b"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/lime_logo_small.jpg\" alt=\"lime\" style=\"width: 400px; float: left\"/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "# The LIME algorithm\n",
    "Ribeiro et al, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__GOAL__: understand the prediction of an arbitrary model for a certrain sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__L__ ocally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- explenations must correspond to how the model behaves __in the neigborhood__ of the instance being predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__I__ nterpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- provide __qualitative understanding__ between the input variables and the response\n",
    "- interpretability must take into account the __user’s limitations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__M__ odel-agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- explainer should be able to explain __any__ model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__E__ xplanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "95db97dd-3f7f-42ea-8126-1103259ce7c2"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- High-level idea: _Approximate_ a complicated model $f$ _locally_ by an interpretable\n",
    "  model $g$. You can go global again to gain trust in the full model,\n",
    "  but this is out of scope here --> see paper.\n",
    "- We want to explain the prediction of the model for a single sample s.\n",
    "- Sample from the neighborhood of s weighted by distance kernel (exponential\n",
    "  kernel with cosine distance). This is done as follows:\n",
    "    1. Sample randomly (uniformly) a random number of words $s'$ from the words of $s$.\n",
    "       Weight $s'$ by distance to $s$ in the BoW space.\n",
    "    2. Input $s'$ to $f$ and get the model prediction for the perturbed sample $s'$.\n",
    "    (1. + 2. are done multiple times, e.g. $1000$ times to collect samples)\n",
    "    3. Fit a weighted sparse linear model $g$ which uses at most $K$ features.\n",
    "       (this step limits the complexity of the model)\n",
    "    4. Get the weights of $g$ to explain the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generate a fake dataset $X$ from the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Use trained black-box model $f$ to get predictions $y_p$ for each example in a generated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Train a white-box model $g$ on $X, y_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Using generated dataset and generated labels as training data. It means we’re trying to create an estimator which works the same as a black-box estimator, but which is easier to inspect. It doesn’t have to work well globally, but it must approximate the black-box model well in the area close to the original example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To express “area close to the original example” user must provide a distance/similarity metric for examples in a generated dataset. Then training data is weighted according to a distance from the original example - the further is example, the less it affects weights of a white-box estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Explain the original example through weights of the white-box model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Assess how well the white-box model approximates the black-box model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    " If the quality is low then explanation shouldn’t be trusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/lime.png\" alt=\"lime\" style=\"width: 800px;\"/>Source: Ribeiro et al, 2016</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's look at an example: the 20 newsgroup data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True,\n",
    "                                  random_state=42, remove=('headers', 'footers'))\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True,\n",
    "                                 random_state=42, remove=('headers', 'footers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: alt.atheism\n",
      "--------------------\n",
      "\n",
      "In article <1993Apr3.153552.4334@mac.cc.macalstr.edu>, acooper@mac.cc.macalstr.edu writes:\n",
      "|> In article <1pint5$1l4@fido.asd.sgi.com>, livesey@solntze.wpd.sgi.com (Jon Livesey) writes\n",
      ">\n",
      "> Well, Germany was hardly the ONLY country to discriminate against the \n",
      "> Jews, although it has the worst reputation because it did the best job \n",
      "> of expressing a general European dislike of them.  This should not turn \n",
      "> into a debate on antisemitism, but you should also point out that Luther's\n",
      ">  antiSemitism was based on religious grounds, while Hitler's was on racial \n",
      "> grounds, and Wagnmer's on aesthetic grounds.  Just blanketing the whole \n",
      "> group is poor analysis, even if they all are bigots.\n",
      "\n",
      "I find these to be intriguing remarks.   Could you give us a bit\n",
      "more explanation here?   For example, which religion is anti-semitic,\n",
      "and which aesthetic?\n"
     ]
    }
   ],
   "source": [
    "i = 125\n",
    "print(\"Class: {}\".format(twenty_train.target_names[twenty_train.target[i]]))\n",
    "print(\"-\"*20); print()\n",
    "sample = twenty_train.data[i]; print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We train a black-box classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.0%\n"
     ]
    }
   ],
   "source": [
    "# LSA features\n",
    "vec = TfidfVectorizer(min_df=3, stop_words='english', ngram_range=(1, 2))\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "lsa = make_pipeline(vec, svd)\n",
    "\n",
    "# SVM with rbf-kernel\n",
    "clf = SVC(C=150, gamma=2e-2, probability=True, kernel=\"rbf\")\n",
    "text_clf = make_pipeline(lsa, clf)\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "print(\"Accuracy: {:.1%}\".format(text_clf.score(twenty_test.data, twenty_test.target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Let's explain the predictions of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_perturbed_sample(sample):\n",
    "    '''Sample words from the text sample uniformly.'''\n",
    "    words = sample.split(\" \")\n",
    "    n_words = random.randrange(0, len(words))\n",
    "    idx = random.sample(list(range(0,len(words))), k=n_words)\n",
    "    return \" \".join([words[i] for i in sorted(idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In article <1993Apr3.153552.4334@mac.cc.macalstr.edu>, acooper@mac.cc.macalstr.edu writes:\n",
      "|> In article <1pint5$1l4@fido.asd.sgi.com>, livesey@solntze.wpd.sgi.com (Jon Livesey) writes\n",
      ">\n",
      "> Well, Germany was hardly the ONLY country to discriminate against the \n",
      "> Jews, although it has the worst reputation because it did the best job \n",
      "> of expressing a general European dislike of them.  This should not turn \n",
      "> into a debate on antisemitism, but you should also point out that Luther's\n",
      ">  antiSemitism was based on religious grounds, while Hitler's was on racial \n",
      "> grounds, and Wagnmer's on aesthetic grounds.  Just blanketing the whole \n",
      "> group is poor analysis, even if they all are bigots.\n",
      "\n",
      "I find these to be intriguing remarks.   Could you give us a bit\n",
      "more explanation here?   For example, which religion is anti-semitic,\n",
      "and which aesthetic?\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Look at a perturbed sample to this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article writes:\n",
      "|> In article Livesey) Well, discriminate against the has it \n",
      "> a them. not into but you out based religious grounds, while and aesthetic even these For which anti-semitic,\n",
      "and aesthetic?\n"
     ]
    }
   ],
   "source": [
    "print(get_perturbed_sample(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Setup the explainer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "explainer = Pipeline([\n",
    "    (\"BoW\", CountVectorizer()),                       # interpretable representation\n",
    "    (\"selectK\", SelectKBest(k=10, score_func=chi2)),  # limit the complexity of the explanation\n",
    "    (\"lr\", LogisticRegression())                      # weighted interpretable model\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Get a lot of perturbed samples and predict on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "perturbed_samples = [get_perturbed_sample(sample) for i in range(5000)]\n",
    "perturbed_predictions = text_clf.predict(perturbed_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Fit the explainer model on the predictions of the text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tobias/anaconda3/envs/dev/lib/python3.6/site-packages/scipy/spatial/distance.py:649: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(binary=True)\n",
    "sigma = 1.0\n",
    "samples_vec = vec.fit_transform(perturbed_samples); samples_vec = samples_vec.todense()\n",
    "weights = np.nan_to_num([np.exp(-distance.cosine(vec.transform([sample]).todense()[0], s)**2 / sigma**2) for s in samples_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('BoW', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.fit(perturbed_samples, perturbed_predictions, lr__sample_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How well does it approximate the black-box model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 89.6%\n"
     ]
    }
   ],
   "source": [
    "new_pert_samples = [get_perturbed_sample(sample) for i in range(1000)]\n",
    "print(\"Score: {:.1%}\".format(explainer.score(new_pert_samples, text_clf.predict(new_pert_samples))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now get the important features/words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inv_vocab = {v: k for k, v in explainer.steps[0][1].vocabulary_.items()}\n",
    "important_words = [inv_vocab[i] for i in explainer.steps[1][1].pvalues_.argsort()[:10][::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Look at the explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> alt.atheism\n",
      "probability: 100.0%\n",
      "--------------------\n",
      "cc: 1.07\n",
      "article: 2.02\n",
      "writes: 0.259\n",
      "was: 2.12\n",
      "grounds: 0.168\n",
      "livesey: 0.211\n",
      "sgi: 2.02\n",
      "com: 0.348\n",
      "on: 0.116\n",
      "the: 1.5\n",
      "\n",
      "> comp.graphics\n",
      "probability: 0.0%\n",
      "--------------------\n",
      "cc: -1.05\n",
      "article: -1.62\n",
      "writes: -0.363\n",
      "was: -1.37\n",
      "grounds: 1.08\n",
      "livesey: -0.22\n",
      "sgi: -1.62\n",
      "com: -0.341\n",
      "on: -0.318\n",
      "the: -1.36\n",
      "\n",
      "> sci.med\n",
      "probability: 0.0%\n",
      "--------------------\n",
      "cc: 0.182\n",
      "article: -1.54\n",
      "writes: 0.215\n",
      "was: -2.46\n",
      "grounds: -2.97\n",
      "livesey: -0.225\n",
      "sgi: -1.54\n",
      "com: -0.0961\n",
      "on: -0.262\n",
      "the: -0.553\n",
      "\n",
      "> soc.religion.christian\n",
      "probability: 0.0%\n",
      "--------------------\n",
      "cc: -1.85\n",
      "article: -1.4\n",
      "writes: -0.304\n",
      "was: -1.39\n",
      "grounds: -2.51\n",
      "livesey: 0.111\n",
      "sgi: -1.4\n",
      "com: -0.101\n",
      "on: 0.608\n",
      "the: -1.11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = explainer.predict_proba([sample])[0]\n",
    "for c in explainer.steps[2][1].classes_:\n",
    "    print(\"> {}\".format(twenty_train.target_names[c]))\n",
    "    print(f\"probability: {p[c]:.1%}\"); print(\"-\"*20)\n",
    "    for w, v in zip(important_words, explainer.steps[2][1].coef_[c]):\n",
    "        print(f\"{w}: {v:.3}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In article <1993Apr3.153552.4334@mac.cc.macalstr.edu>, acooper@mac.cc.macalstr.edu writes:\n",
      "|> In article <1pint5$1l4@fido.asd.sgi.com>, livesey@solntze.wpd.sgi.com (Jon Livesey) writes\n",
      ">\n",
      "> Well, Germany was hardly the ONLY country to discriminate against the \n",
      "> Jews, although it has the worst reputation because it did the best job \n",
      "> of expressing a general European dislike of them.  This should not turn \n",
      "> into a debate on antisemitism, but you should also point out that Luther's\n",
      ">  antiSemitism was based on religious grounds, while Hitler's was on racial \n",
      "> grounds, and Wagnmer's on aesthetic grounds.  Just blanketing the whole \n",
      "> group is poor analysis, even if they all are bigots.\n",
      "\n",
      "I find these to be intriguing remarks.   Could you give us a bit\n",
      "more explanation here?   For example, which religion is anti-semitic,\n",
      "and which aesthetic?\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8d0ef5a1-da05-46a1-abe1-329eb9e9c3b5"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's look at eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- python package: https://github.com/TeamHG-Memex/eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- provides insights in different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- provides nice visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- allows for multiple different explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- kernel density estimation to get better perturbed samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "29820824-94ae-4f99-9ccc-0616d3583335"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=alt.atheism\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.999</b>, score <b>8.880</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.421\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.542\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"opacity: 0.80\">in </span><span style=\"background-color: hsl(120, 100.00%, 73.62%); opacity: 0.91\" title=\"0.569\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(120, 100.00%, 80.99%); opacity: 0.87\" title=\"0.356\">1993apr3</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.46%); opacity: 0.82\" title=\"0.078\">153552</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 94.01%); opacity: 0.81\" title=\"0.069\">4334</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 72.76%); opacity: 0.92\" title=\"-0.595\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 94.27%); opacity: 0.81\" title=\"-0.064\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 88.40%); opacity: 0.83\" title=\"-0.176\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 71.32%); opacity: 0.92\" title=\"0.641\">edu</span><span style=\"opacity: 0.80\">&gt;, acooper@</span><span style=\"background-color: hsl(0, 100.00%, 72.76%); opacity: 0.92\" title=\"-0.595\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 94.27%); opacity: 0.81\" title=\"-0.064\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 88.40%); opacity: 0.83\" title=\"-0.176\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 71.32%); opacity: 0.92\" title=\"0.641\">edu</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.75%); opacity: 0.91\" title=\"0.565\">writes</span><span style=\"opacity: 0.80\">:\n",
       "|&gt; in </span><span style=\"background-color: hsl(120, 100.00%, 78.63%); opacity: 0.88\" title=\"0.421\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(120, 100.00%, 96.60%); opacity: 0.81\" title=\"0.031\">1pint5</span><span style=\"opacity: 0.80\">$</span><span style=\"background-color: hsl(0, 100.00%, 97.75%); opacity: 0.80\" title=\"-0.017\">1l4</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(120, 100.00%, 94.02%); opacity: 0.81\" title=\"0.068\">fido</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 88.44%); opacity: 0.83\" title=\"0.175\">asd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 79.75%); opacity: 0.88\" title=\"0.390\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 61.32%); opacity: 0.99\" title=\"0.983\">com</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(120, 100.00%, 64.27%); opacity: 0.97\" title=\"0.878\">livesey</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(120, 100.00%, 75.29%); opacity: 0.90\" title=\"0.518\">solntze</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 65.29%); opacity: 0.96\" title=\"0.842\">wpd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 71.02%); opacity: 0.93\" title=\"0.651\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"1.031\">com</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(120, 100.00%, 77.96%); opacity: 0.89\" title=\"0.440\">jon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.79%); opacity: 0.96\" title=\"0.825\">livesey</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 70.00%); opacity: 0.93\" title=\"0.684\">writes</span><span style=\"opacity: 0.80\">\n",
       "&gt;\n",
       "&gt; well, </span><span style=\"background-color: hsl(120, 100.00%, 88.87%); opacity: 0.83\" title=\"0.166\">germany</span><span style=\"opacity: 0.80\"> was </span><span style=\"background-color: hsl(120, 100.00%, 91.97%); opacity: 0.82\" title=\"0.104\">hardly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.99%); opacity: 0.80\" title=\"-0.000\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.05%); opacity: 0.81\" title=\"0.068\">only</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.44%); opacity: 0.84\" title=\"0.197\">country</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(0, 100.00%, 90.85%); opacity: 0.82\" title=\"-0.125\">discriminate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.25%); opacity: 0.81\" title=\"0.049\">against</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.00%); opacity: 0.80\" title=\"-0.026\">the</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 83.50%); opacity: 0.86\" title=\"0.291\">jews</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 95.49%); opacity: 0.81\" title=\"-0.046\">although</span><span style=\"opacity: 0.80\"> it has </span><span style=\"background-color: hsl(0, 100.00%, 97.00%); opacity: 0.80\" title=\"-0.026\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.04%); opacity: 0.80\" title=\"0.005\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.38%); opacity: 0.80\" title=\"0.011\">reputation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.65%); opacity: 0.81\" title=\"-0.030\">because</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.67%); opacity: 0.81\" title=\"0.058\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.20%); opacity: 0.85\" title=\"0.274\">did</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.00%); opacity: 0.80\" title=\"-0.026\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.47%); opacity: 0.82\" title=\"-0.113\">best</span><span style=\"opacity: 0.80\"> job \n",
       "&gt; of </span><span style=\"background-color: hsl(0, 100.00%, 93.06%); opacity: 0.82\" title=\"-0.084\">expressing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.52%); opacity: 0.80\" title=\"-0.019\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.65%); opacity: 0.83\" title=\"0.171\">general</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.75%); opacity: 0.82\" title=\"0.127\">european</span><span style=\"opacity: 0.80\"> dislike of </span><span style=\"background-color: hsl(0, 100.00%, 96.87%); opacity: 0.81\" title=\"-0.027\">them</span><span style=\"opacity: 0.80\">.  this should not </span><span style=\"background-color: hsl(0, 100.00%, 97.16%); opacity: 0.80\" title=\"-0.024\">turn</span><span style=\"opacity: 0.80\"> \n",
       "&gt; into a debate on </span><span style=\"background-color: hsl(0, 100.00%, 91.32%); opacity: 0.82\" title=\"-0.116\">antisemitism</span><span style=\"opacity: 0.80\">, but you should also </span><span style=\"background-color: hsl(120, 100.00%, 91.11%); opacity: 0.82\" title=\"0.120\">point</span><span style=\"opacity: 0.80\"> out that </span><span style=\"background-color: hsl(0, 100.00%, 94.99%); opacity: 0.81\" title=\"-0.053\">luther</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 96.15%); opacity: 0.81\" title=\"-0.036\">s</span><span style=\"opacity: 0.80\">\n",
       "&gt;  </span><span style=\"background-color: hsl(0, 100.00%, 93.07%); opacity: 0.82\" title=\"-0.084\">antisemitism</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.49%); opacity: 0.81\" title=\"0.032\">was</span><span style=\"opacity: 0.80\"> based on </span><span style=\"background-color: hsl(120, 100.00%, 66.03%); opacity: 0.96\" title=\"0.816\">religious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.76%); opacity: 0.80\" title=\"-0.007\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.62%); opacity: 0.81\" title=\"0.044\">while</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.75%); opacity: 0.84\" title=\"0.190\">hitler</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 95.61%); opacity: 0.81\" title=\"0.044\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.30%); opacity: 0.82\" title=\"0.080\">was</span><span style=\"opacity: 0.80\"> on </span><span style=\"background-color: hsl(0, 100.00%, 96.83%); opacity: 0.81\" title=\"-0.028\">racial</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 91.88%); opacity: 0.82\" title=\"-0.106\">grounds</span><span style=\"opacity: 0.80\">, and wagnmer&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 96.15%); opacity: 0.81\" title=\"-0.036\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.45%); opacity: 0.81\" title=\"-0.032\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.64%); opacity: 0.84\" title=\"-0.215\">aesthetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.28%); opacity: 0.81\" title=\"-0.064\">grounds</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 85.13%); opacity: 0.85\" title=\"0.251\">just</span><span style=\"opacity: 0.80\"> blanketing </span><span style=\"background-color: hsl(0, 100.00%, 97.00%); opacity: 0.80\" title=\"-0.026\">the</span><span style=\"opacity: 0.80\"> whole \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 86.48%); opacity: 0.84\" title=\"0.219\">group</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(120, 100.00%, 95.20%); opacity: 0.81\" title=\"0.050\">poor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.35%); opacity: 0.84\" title=\"-0.222\">analysis</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.29%); opacity: 0.82\" title=\"-0.080\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.29%); opacity: 0.82\" title=\"-0.080\">if</span><span style=\"opacity: 0.80\"> they </span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.082\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.15%); opacity: 0.81\" title=\"0.066\">are</span><span style=\"opacity: 0.80\"> bigots.\n",
       "\n",
       "i find </span><span style=\"background-color: hsl(120, 100.00%, 97.02%); opacity: 0.80\" title=\"0.025\">these</span><span style=\"opacity: 0.80\"> to be </span><span style=\"background-color: hsl(0, 100.00%, 90.45%); opacity: 0.83\" title=\"-0.133\">intriguing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.45%); opacity: 0.83\" title=\"-0.133\">remarks</span><span style=\"opacity: 0.80\">.   could you give us a </span><span style=\"background-color: hsl(0, 100.00%, 80.49%); opacity: 0.87\" title=\"-0.370\">bit</span><span style=\"opacity: 0.80\">\n",
       "more </span><span style=\"background-color: hsl(0, 100.00%, 97.97%); opacity: 0.80\" title=\"-0.015\">explanation</span><span style=\"opacity: 0.80\"> here?   for </span><span style=\"background-color: hsl(120, 100.00%, 83.15%); opacity: 0.86\" title=\"0.300\">example</span><span style=\"opacity: 0.80\">, which </span><span style=\"background-color: hsl(120, 100.00%, 63.59%); opacity: 0.97\" title=\"0.901\">religion</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(120, 100.00%, 93.41%); opacity: 0.82\" title=\"0.079\">anti</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 92.32%); opacity: 0.82\" title=\"-0.098\">semitic</span><span style=\"opacity: 0.80\">,\n",
       "and which </span><span style=\"background-color: hsl(0, 100.00%, 88.08%); opacity: 0.84\" title=\"-0.183\">aesthetic</span><span style=\"opacity: 0.80\">?</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=comp.graphics\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.000</b>, score <b>-7.740</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.81%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.016\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -7.725\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"opacity: 0.80\">in </span><span style=\"background-color: hsl(0, 100.00%, 79.60%); opacity: 0.88\" title=\"-0.394\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(0, 100.00%, 87.81%); opacity: 0.84\" title=\"-0.189\">1993apr3</span><span style=\"opacity: 0.80\">.153552.4334@</span><span style=\"background-color: hsl(120, 100.00%, 62.35%); opacity: 0.98\" title=\"0.946\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 81.47%); opacity: 0.87\" title=\"0.343\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.175\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 75.49%); opacity: 0.90\" title=\"-0.512\">edu</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(120, 100.00%, 93.83%); opacity: 0.81\" title=\"0.071\">acooper</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(120, 100.00%, 60.39%); opacity: 1.00\" title=\"1.017\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 81.47%); opacity: 0.87\" title=\"0.343\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 88.45%); opacity: 0.83\" title=\"0.175\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 73.88%); opacity: 0.91\" title=\"-0.561\">edu</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.13%); opacity: 0.91\" title=\"-0.553\">writes</span><span style=\"opacity: 0.80\">:\n",
       "|&gt; </span><span style=\"background-color: hsl(120, 100.00%, 96.23%); opacity: 0.81\" title=\"0.035\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.05%); opacity: 0.87\" title=\"-0.382\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(0, 100.00%, 91.27%); opacity: 0.82\" title=\"-0.117\">1pint5</span><span style=\"opacity: 0.80\">$</span><span style=\"background-color: hsl(0, 100.00%, 94.88%); opacity: 0.81\" title=\"-0.055\">1l4</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 95.05%); opacity: 0.81\" title=\"-0.052\">fido</span><span style=\"opacity: 0.80\">.asd.</span><span style=\"background-color: hsl(120, 100.00%, 98.68%); opacity: 0.80\" title=\"0.008\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 63.17%); opacity: 0.98\" title=\"-0.916\">com</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(0, 100.00%, 71.03%); opacity: 0.93\" title=\"-0.650\">livesey</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 81.94%); opacity: 0.86\" title=\"-0.331\">solntze</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 71.14%); opacity: 0.93\" title=\"-0.647\">wpd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 85.11%); opacity: 0.85\" title=\"-0.251\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 61.95%); opacity: 0.99\" title=\"-0.960\">com</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(0, 100.00%, 81.65%); opacity: 0.87\" title=\"-0.339\">jon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.75%); opacity: 0.93\" title=\"-0.692\">livesey</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(0, 100.00%, 70.59%); opacity: 0.93\" title=\"-0.665\">writes</span><span style=\"opacity: 0.80\">\n",
       "&gt;\n",
       "&gt; well, </span><span style=\"background-color: hsl(0, 100.00%, 88.61%); opacity: 0.83\" title=\"-0.171\">germany</span><span style=\"opacity: 0.80\"> was </span><span style=\"background-color: hsl(0, 100.00%, 87.65%); opacity: 0.84\" title=\"-0.192\">hardly</span><span style=\"opacity: 0.80\"> the only </span><span style=\"background-color: hsl(0, 100.00%, 89.44%); opacity: 0.83\" title=\"-0.154\">country</span><span style=\"opacity: 0.80\"> to </span><span style=\"background-color: hsl(120, 100.00%, 91.05%); opacity: 0.82\" title=\"0.121\">discriminate</span><span style=\"opacity: 0.80\"> against the \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 77.79%); opacity: 0.89\" title=\"-0.445\">jews</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.24%); opacity: 0.81\" title=\"0.049\">although</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.94%); opacity: 0.80\" title=\"0.006\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.18%); opacity: 0.81\" title=\"0.036\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.69%); opacity: 0.80\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.25%); opacity: 0.81\" title=\"0.049\">worst</span><span style=\"opacity: 0.80\"> reputation </span><span style=\"background-color: hsl(0, 100.00%, 95.25%); opacity: 0.81\" title=\"-0.049\">because</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.40%); opacity: 0.81\" title=\"-0.062\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.94%); opacity: 0.86\" title=\"-0.305\">did</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.38%); opacity: 0.82\" title=\"0.096\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.74%); opacity: 0.81\" title=\"0.042\">best</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.96%); opacity: 0.82\" title=\"0.086\">job</span><span style=\"opacity: 0.80\"> \n",
       "&gt; of </span><span style=\"background-color: hsl(120, 100.00%, 96.13%); opacity: 0.81\" title=\"0.037\">expressing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.13%); opacity: 0.81\" title=\"0.037\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.22%); opacity: 0.83\" title=\"-0.159\">general</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.64%); opacity: 0.81\" title=\"0.044\">european</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.26%); opacity: 0.82\" title=\"0.099\">dislike</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 96.16%); opacity: 0.81\" title=\"0.036\">them</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 97.44%); opacity: 0.80\" title=\"0.020\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.84%); opacity: 0.80\" title=\"-0.016\">should</span><span style=\"opacity: 0.80\"> not </span><span style=\"background-color: hsl(120, 100.00%, 96.75%); opacity: 0.81\" title=\"0.029\">turn</span><span style=\"opacity: 0.80\"> \n",
       "&gt; into a debate </span><span style=\"background-color: hsl(0, 100.00%, 95.22%); opacity: 0.81\" title=\"-0.050\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.48%); opacity: 0.81\" title=\"0.077\">antisemitism</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.86%); opacity: 0.81\" title=\"0.071\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.86%); opacity: 0.81\" title=\"0.071\">you</span><span style=\"opacity: 0.80\"> should also </span><span style=\"background-color: hsl(0, 100.00%, 91.24%); opacity: 0.82\" title=\"-0.118\">point</span><span style=\"opacity: 0.80\"> out that luther&#x27;s\n",
       "&gt;  </span><span style=\"background-color: hsl(120, 100.00%, 93.48%); opacity: 0.81\" title=\"0.077\">antisemitism</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.85%); opacity: 0.81\" title=\"0.071\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.85%); opacity: 0.81\" title=\"0.071\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.22%); opacity: 0.81\" title=\"-0.050\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.36%); opacity: 0.98\" title=\"-0.910\">religious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.00%); opacity: 0.81\" title=\"-0.053\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 94.83%); opacity: 0.81\" title=\"0.055\">while</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.39%); opacity: 0.83\" title=\"-0.134\">hitler</span><span style=\"opacity: 0.80\">&#x27;s was </span><span style=\"background-color: hsl(0, 100.00%, 95.22%); opacity: 0.81\" title=\"-0.050\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.75%); opacity: 0.81\" title=\"0.042\">racial</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 98.34%); opacity: 0.80\" title=\"-0.011\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 98.42%); opacity: 0.80\" title=\"-0.010\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.30%); opacity: 0.83\" title=\"-0.157\">wagnmer</span><span style=\"opacity: 0.80\">&#x27;s </span><span style=\"background-color: hsl(120, 100.00%, 95.56%); opacity: 0.81\" title=\"0.045\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.11%); opacity: 0.82\" title=\"0.101\">aesthetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.00%); opacity: 0.81\" title=\"-0.053\">grounds</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(0, 100.00%, 84.70%); opacity: 0.85\" title=\"-0.261\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.88%); opacity: 0.81\" title=\"0.027\">blanketing</span><span style=\"opacity: 0.80\"> the </span><span style=\"background-color: hsl(120, 100.00%, 95.70%); opacity: 0.81\" title=\"0.043\">whole</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 87.96%); opacity: 0.84\" title=\"-0.186\">group</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 95.00%); opacity: 0.81\" title=\"-0.053\">poor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.14%); opacity: 0.86\" title=\"0.300\">analysis</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 95.42%); opacity: 0.81\" title=\"0.047\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.32%); opacity: 0.81\" title=\"0.063\">if</span><span style=\"opacity: 0.80\"> they </span><span style=\"background-color: hsl(0, 100.00%, 92.57%); opacity: 0.82\" title=\"-0.093\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.39%); opacity: 0.81\" title=\"-0.062\">are</span><span style=\"opacity: 0.80\"> bigots.\n",
       "\n",
       "i find these to be </span><span style=\"background-color: hsl(120, 100.00%, 91.18%); opacity: 0.82\" title=\"0.119\">intriguing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.18%); opacity: 0.82\" title=\"0.119\">remarks</span><span style=\"opacity: 0.80\">.   could you </span><span style=\"background-color: hsl(0, 100.00%, 96.67%); opacity: 0.81\" title=\"-0.030\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.38%); opacity: 0.81\" title=\"-0.033\">us</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 76.56%); opacity: 0.89\" title=\"0.480\">bit</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 97.51%); opacity: 0.80\" title=\"-0.020\">more</span><span style=\"opacity: 0.80\"> explanation </span><span style=\"background-color: hsl(120, 100.00%, 96.09%); opacity: 0.81\" title=\"0.037\">here</span><span style=\"opacity: 0.80\">?   </span><span style=\"background-color: hsl(120, 100.00%, 96.09%); opacity: 0.81\" title=\"0.037\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.67%); opacity: 0.88\" title=\"-0.392\">example</span><span style=\"opacity: 0.80\">, which </span><span style=\"background-color: hsl(0, 100.00%, 60.51%); opacity: 1.00\" title=\"-1.012\">religion</span><span style=\"opacity: 0.80\"> is </span><span style=\"background-color: hsl(0, 100.00%, 88.22%); opacity: 0.83\" title=\"-0.180\">anti</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 92.68%); opacity: 0.82\" title=\"0.091\">semitic</span><span style=\"opacity: 0.80\">,\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 95.42%); opacity: 0.81\" title=\"0.047\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.54%); opacity: 0.83\" title=\"0.152\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.06%); opacity: 0.82\" title=\"0.102\">aesthetic</span><span style=\"opacity: 0.80\">?</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=sci.med\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.000</b>, score <b>-12.524</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.196\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -12.328\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 97.01%); opacity: 0.80\" title=\"-0.025\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.46%); opacity: 0.83\" title=\"-0.153\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(0, 100.00%, 86.37%); opacity: 0.84\" title=\"-0.221\">1993apr3</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 88.01%); opacity: 0.84\" title=\"-0.184\">153552</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 93.12%); opacity: 0.82\" title=\"-0.083\">4334</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 82.45%); opacity: 0.86\" title=\"-0.318\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 83.93%); opacity: 0.85\" title=\"-0.280\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 94.30%); opacity: 0.81\" title=\"0.064\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 86.61%); opacity: 0.84\" title=\"-0.216\">edu</span><span style=\"opacity: 0.80\">&gt;, acooper@</span><span style=\"background-color: hsl(0, 100.00%, 81.62%); opacity: 0.87\" title=\"-0.340\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 83.93%); opacity: 0.85\" title=\"-0.280\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 94.30%); opacity: 0.81\" title=\"0.064\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 86.61%); opacity: 0.84\" title=\"-0.216\">edu</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.65%); opacity: 0.85\" title=\"-0.263\">writes</span><span style=\"opacity: 0.80\">:\n",
       "|&gt; </span><span style=\"background-color: hsl(0, 100.00%, 97.01%); opacity: 0.80\" title=\"-0.025\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.46%); opacity: 0.83\" title=\"-0.153\">article</span><span style=\"opacity: 0.80\"> &lt;1pint5$1l4@</span><span style=\"background-color: hsl(0, 100.00%, 91.30%); opacity: 0.82\" title=\"-0.117\">fido</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 87.25%); opacity: 0.84\" title=\"-0.201\">asd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 65.95%); opacity: 0.96\" title=\"-0.819\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 92.45%); opacity: 0.82\" title=\"-0.095\">com</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(0, 100.00%, 65.03%); opacity: 0.97\" title=\"-0.851\">livesey</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 79.66%); opacity: 0.88\" title=\"-0.392\">solntze</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 78.28%); opacity: 0.88\" title=\"-0.431\">wpd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 65.95%); opacity: 0.96\" title=\"-0.819\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 93.49%); opacity: 0.81\" title=\"-0.077\">com</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(0, 100.00%, 82.14%); opacity: 0.86\" title=\"-0.326\">jon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 65.56%); opacity: 0.96\" title=\"-0.833\">livesey</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(0, 100.00%, 84.65%); opacity: 0.85\" title=\"-0.263\">writes</span><span style=\"opacity: 0.80\">\n",
       "&gt;\n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 96.04%); opacity: 0.81\" title=\"-0.038\">well</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 85.10%); opacity: 0.85\" title=\"-0.252\">germany</span><span style=\"opacity: 0.80\"> was </span><span style=\"background-color: hsl(120, 100.00%, 96.53%); opacity: 0.81\" title=\"0.031\">hardly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.61%); opacity: 0.81\" title=\"-0.030\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.17%); opacity: 0.81\" title=\"-0.066\">only</span><span style=\"opacity: 0.80\"> country </span><span style=\"background-color: hsl(0, 100.00%, 91.82%); opacity: 0.82\" title=\"-0.107\">to</span><span style=\"opacity: 0.80\"> discriminate </span><span style=\"background-color: hsl(0, 100.00%, 93.73%); opacity: 0.81\" title=\"-0.073\">against</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.84%); opacity: 0.81\" title=\"-0.027\">the</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 82.11%); opacity: 0.86\" title=\"-0.327\">jews</span><span style=\"opacity: 0.80\">, although </span><span style=\"background-color: hsl(0, 100.00%, 93.89%); opacity: 0.81\" title=\"-0.070\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.85%); opacity: 0.82\" title=\"-0.088\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.42%); opacity: 0.81\" title=\"-0.062\">the</span><span style=\"opacity: 0.80\"> worst reputation </span><span style=\"background-color: hsl(120, 100.00%, 94.69%); opacity: 0.81\" title=\"0.058\">because</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.89%); opacity: 0.81\" title=\"-0.070\">it</span><span style=\"opacity: 0.80\"> did </span><span style=\"background-color: hsl(0, 100.00%, 94.42%); opacity: 0.81\" title=\"-0.062\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.09%); opacity: 0.80\" title=\"0.024\">best</span><span style=\"opacity: 0.80\"> job \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 88.87%); opacity: 0.83\" title=\"-0.166\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.19%); opacity: 0.85\" title=\"0.249\">expressing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.95%); opacity: 0.84\" title=\"0.186\">a</span><span style=\"opacity: 0.80\"> general european </span><span style=\"background-color: hsl(0, 100.00%, 86.75%); opacity: 0.84\" title=\"-0.213\">dislike</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.87%); opacity: 0.83\" title=\"-0.166\">of</span><span style=\"opacity: 0.80\"> them.  this should </span><span style=\"background-color: hsl(0, 100.00%, 99.52%); opacity: 0.80\" title=\"-0.002\">not</span><span style=\"opacity: 0.80\"> turn \n",
       "&gt; into a debate on antisemitism, but </span><span style=\"background-color: hsl(0, 100.00%, 92.46%); opacity: 0.82\" title=\"-0.095\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.40%); opacity: 0.80\" title=\"0.010\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.03%); opacity: 0.81\" title=\"-0.068\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.61%); opacity: 0.83\" title=\"-0.130\">point</span><span style=\"opacity: 0.80\"> out that </span><span style=\"background-color: hsl(0, 100.00%, 96.18%); opacity: 0.81\" title=\"-0.036\">luther</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 99.44%); opacity: 0.80\" title=\"-0.002\">s</span><span style=\"opacity: 0.80\">\n",
       "&gt;  antisemitism was </span><span style=\"background-color: hsl(0, 100.00%, 85.25%); opacity: 0.85\" title=\"-0.248\">based</span><span style=\"opacity: 0.80\"> on </span><span style=\"background-color: hsl(0, 100.00%, 76.08%); opacity: 0.90\" title=\"-0.495\">religious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.49%); opacity: 0.82\" title=\"0.095\">grounds</span><span style=\"opacity: 0.80\">, while </span><span style=\"background-color: hsl(0, 100.00%, 89.30%); opacity: 0.83\" title=\"-0.157\">hitler</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 99.44%); opacity: 0.80\" title=\"-0.002\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.39%); opacity: 0.82\" title=\"0.115\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.13%); opacity: 0.83\" title=\"0.160\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.83%); opacity: 0.80\" title=\"0.007\">racial</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 89.22%); opacity: 0.83\" title=\"0.158\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.36%); opacity: 0.80\" title=\"-0.021\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.16%); opacity: 0.83\" title=\"0.139\">wagnmer</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 90.28%); opacity: 0.83\" title=\"0.137\">s</span><span style=\"opacity: 0.80\"> on </span><span style=\"background-color: hsl(120, 100.00%, 92.93%); opacity: 0.82\" title=\"0.087\">aesthetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.49%); opacity: 0.82\" title=\"0.095\">grounds</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(0, 100.00%, 88.11%); opacity: 0.84\" title=\"-0.182\">just</span><span style=\"opacity: 0.80\"> blanketing </span><span style=\"background-color: hsl(0, 100.00%, 94.42%); opacity: 0.81\" title=\"-0.062\">the</span><span style=\"opacity: 0.80\"> whole \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 90.91%); opacity: 0.82\" title=\"-0.124\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.53%); opacity: 0.83\" title=\"-0.152\">is</span><span style=\"opacity: 0.80\"> poor </span><span style=\"background-color: hsl(0, 100.00%, 92.59%); opacity: 0.82\" title=\"-0.093\">analysis</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.61%); opacity: 0.81\" title=\"0.075\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.64%); opacity: 0.83\" title=\"0.130\">if</span><span style=\"opacity: 0.80\"> they </span><span style=\"background-color: hsl(0, 100.00%, 92.32%); opacity: 0.82\" title=\"-0.098\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.89%); opacity: 0.80\" title=\"0.006\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.73%); opacity: 0.80\" title=\"0.007\">bigots</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.29%); opacity: 0.81\" title=\"-0.064\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.31%); opacity: 0.83\" title=\"-0.156\">find</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.077\">these</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.82%); opacity: 0.82\" title=\"-0.107\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.09%); opacity: 0.83\" title=\"-0.141\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.96%); opacity: 0.82\" title=\"0.086\">intriguing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.96%); opacity: 0.82\" title=\"0.086\">remarks</span><span style=\"opacity: 0.80\">.   </span><span style=\"background-color: hsl(0, 100.00%, 98.09%); opacity: 0.80\" title=\"-0.013\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.32%); opacity: 0.82\" title=\"-0.098\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.68%); opacity: 0.80\" title=\"0.008\">give</span><span style=\"opacity: 0.80\"> us a </span><span style=\"background-color: hsl(0, 100.00%, 89.63%); opacity: 0.83\" title=\"-0.150\">bit</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 91.47%); opacity: 0.82\" title=\"-0.113\">more</span><span style=\"opacity: 0.80\"> explanation here?   </span><span style=\"background-color: hsl(0, 100.00%, 97.00%); opacity: 0.80\" title=\"-0.025\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.63%); opacity: 0.85\" title=\"-0.239\">example</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.37%); opacity: 0.82\" title=\"-0.079\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.32%); opacity: 0.92\" title=\"-0.641\">religion</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.53%); opacity: 0.83\" title=\"-0.152\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.71%); opacity: 0.88\" title=\"0.391\">anti</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 91.24%); opacity: 0.82\" title=\"0.118\">semitic</span><span style=\"opacity: 0.80\">,\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 93.03%); opacity: 0.82\" title=\"-0.085\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.37%); opacity: 0.82\" title=\"-0.079\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.93%); opacity: 0.82\" title=\"0.087\">aesthetic</span><span style=\"opacity: 0.80\">?</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=soc.religion.christian\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.000</b>, score <b>-9.564</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.215\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -9.348\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 91.50%); opacity: 0.82\" title=\"-0.113\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.45%); opacity: 0.92\" title=\"-0.605\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(0, 100.00%, 85.94%); opacity: 0.84\" title=\"-0.231\">1993apr3</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 98.13%); opacity: 0.80\" title=\"0.013\">153552</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 92.18%); opacity: 0.82\" title=\"-0.100\">4334</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 86.71%); opacity: 0.84\" title=\"-0.214\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 77.20%); opacity: 0.89\" title=\"-0.462\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.028\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 70.24%); opacity: 0.93\" title=\"-0.676\">edu</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(120, 100.00%, 91.46%); opacity: 0.82\" title=\"0.114\">acooper</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 92.19%); opacity: 0.82\" title=\"-0.100\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 77.20%); opacity: 0.89\" title=\"-0.462\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.028\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 70.24%); opacity: 0.93\" title=\"-0.676\">edu</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.14%); opacity: 0.88\" title=\"-0.435\">writes</span><span style=\"opacity: 0.80\">:\n",
       "|&gt; </span><span style=\"background-color: hsl(0, 100.00%, 91.50%); opacity: 0.82\" title=\"-0.113\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.45%); opacity: 0.92\" title=\"-0.605\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(120, 100.00%, 94.10%); opacity: 0.81\" title=\"0.067\">1pint5</span><span style=\"opacity: 0.80\">$</span><span style=\"background-color: hsl(120, 100.00%, 94.84%); opacity: 0.81\" title=\"0.055\">1l4</span><span style=\"opacity: 0.80\">@fido.</span><span style=\"background-color: hsl(0, 100.00%, 91.15%); opacity: 0.82\" title=\"-0.120\">asd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 75.25%); opacity: 0.90\" title=\"-0.519\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 62.36%); opacity: 0.98\" title=\"-0.945\">com</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(0, 100.00%, 75.87%); opacity: 0.90\" title=\"-0.501\">livesey</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 80.72%); opacity: 0.87\" title=\"-0.363\">solntze</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 87.82%); opacity: 0.84\" title=\"-0.189\">wpd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 75.25%); opacity: 0.90\" title=\"-0.519\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 62.36%); opacity: 0.98\" title=\"-0.945\">com</span><span style=\"opacity: 0.80\"> (jon </span><span style=\"background-color: hsl(0, 100.00%, 75.87%); opacity: 0.90\" title=\"-0.501\">livesey</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(0, 100.00%, 78.14%); opacity: 0.88\" title=\"-0.435\">writes</span><span style=\"opacity: 0.80\">\n",
       "&gt;\n",
       "&gt; well, germany </span><span style=\"background-color: hsl(0, 100.00%, 90.91%); opacity: 0.82\" title=\"-0.124\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.02%); opacity: 0.81\" title=\"0.038\">hardly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.46%); opacity: 0.80\" title=\"-0.010\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.54%); opacity: 0.81\" title=\"-0.060\">only</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.92%); opacity: 0.81\" title=\"-0.040\">country</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.03%); opacity: 0.84\" title=\"0.184\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.03%); opacity: 0.84\" title=\"0.184\">discriminate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.69%); opacity: 0.81\" title=\"-0.074\">against</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.70%); opacity: 0.80\" title=\"0.017\">the</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 73.31%); opacity: 0.91\" title=\"0.578\">jews</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 86.54%); opacity: 0.84\" title=\"0.218\">although</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.068\">it</span><span style=\"opacity: 0.80\"> has </span><span style=\"background-color: hsl(0, 100.00%, 93.04%); opacity: 0.82\" title=\"-0.085\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.72%); opacity: 0.80\" title=\"0.001\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.53%); opacity: 0.82\" title=\"0.094\">reputation</span><span style=\"opacity: 0.80\"> because </span><span style=\"background-color: hsl(0, 100.00%, 94.02%); opacity: 0.81\" title=\"-0.068\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.74%); opacity: 0.82\" title=\"0.128\">did</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.04%); opacity: 0.82\" title=\"-0.085\">the</span><span style=\"opacity: 0.80\"> best job \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 91.26%); opacity: 0.82\" title=\"-0.117\">of</span><span style=\"opacity: 0.80\"> expressing </span><span style=\"background-color: hsl(0, 100.00%, 94.73%); opacity: 0.81\" title=\"-0.057\">a</span><span style=\"opacity: 0.80\"> general </span><span style=\"background-color: hsl(0, 100.00%, 91.73%); opacity: 0.82\" title=\"-0.108\">european</span><span style=\"opacity: 0.80\"> dislike </span><span style=\"background-color: hsl(0, 100.00%, 91.26%); opacity: 0.82\" title=\"-0.117\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.58%); opacity: 0.80\" title=\"-0.019\">them</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 87.71%); opacity: 0.84\" title=\"0.191\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.43%); opacity: 0.80\" title=\"-0.002\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.07%); opacity: 0.81\" title=\"-0.052\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.20%); opacity: 0.80\" title=\"0.012\">turn</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 94.23%); opacity: 0.81\" title=\"-0.065\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.71%); opacity: 0.81\" title=\"0.029\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.10%); opacity: 0.84\" title=\"0.182\">debate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.68%); opacity: 0.82\" title=\"0.129\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.97%); opacity: 0.82\" title=\"0.104\">antisemitism</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.48%); opacity: 0.81\" title=\"-0.077\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.68%); opacity: 0.81\" title=\"0.030\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.59%); opacity: 0.81\" title=\"-0.031\">should</span><span style=\"opacity: 0.80\"> also point out that </span><span style=\"background-color: hsl(0, 100.00%, 97.16%); opacity: 0.80\" title=\"-0.024\">luther</span><span style=\"opacity: 0.80\">&#x27;s\n",
       "&gt;  antisemitism </span><span style=\"background-color: hsl(0, 100.00%, 90.91%); opacity: 0.82\" title=\"-0.124\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.56%); opacity: 0.82\" title=\"0.112\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.22%); opacity: 0.82\" title=\"0.118\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.43%); opacity: 0.82\" title=\"0.078\">religious</span><span style=\"opacity: 0.80\"> grounds, </span><span style=\"background-color: hsl(0, 100.00%, 91.74%); opacity: 0.82\" title=\"-0.108\">while</span><span style=\"opacity: 0.80\"> hitler&#x27;s </span><span style=\"background-color: hsl(120, 100.00%, 98.32%); opacity: 0.80\" title=\"0.011\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.31%); opacity: 0.81\" title=\"0.064\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.10%); opacity: 0.83\" title=\"0.140\">racial</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 88.62%); opacity: 0.83\" title=\"0.171\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.57%); opacity: 0.81\" title=\"0.031\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.23%); opacity: 0.82\" title=\"0.099\">wagnmer</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 88.12%); opacity: 0.84\" title=\"0.182\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.32%); opacity: 0.81\" title=\"0.034\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.35%); opacity: 0.84\" title=\"0.222\">aesthetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.36%); opacity: 0.84\" title=\"0.199\">grounds</span><span style=\"opacity: 0.80\">.  just </span><span style=\"background-color: hsl(0, 100.00%, 94.16%); opacity: 0.81\" title=\"-0.066\">blanketing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.65%); opacity: 0.81\" title=\"0.074\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.45%); opacity: 0.87\" title=\"0.344\">whole</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 87.99%); opacity: 0.84\" title=\"0.185\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.18%); opacity: 0.81\" title=\"-0.066\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.73%); opacity: 0.81\" title=\"0.073\">poor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.02%); opacity: 0.81\" title=\"-0.053\">analysis</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 92.98%); opacity: 0.82\" title=\"-0.086\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.35%); opacity: 0.82\" title=\"0.097\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.36%); opacity: 0.80\" title=\"-0.021\">they</span><span style=\"opacity: 0.80\"> all are bigots.\n",
       "\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 95.50%); opacity: 0.81\" title=\"0.045\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.30%); opacity: 0.82\" title=\"0.080\">find</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.58%); opacity: 0.82\" title=\"0.111\">these</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.53%); opacity: 0.81\" title=\"0.076\">to</span><span style=\"opacity: 0.80\"> be </span><span style=\"background-color: hsl(120, 100.00%, 90.15%); opacity: 0.83\" title=\"0.139\">intriguing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.15%); opacity: 0.83\" title=\"0.139\">remarks</span><span style=\"opacity: 0.80\">.   </span><span style=\"background-color: hsl(0, 100.00%, 94.52%); opacity: 0.81\" title=\"-0.060\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.51%); opacity: 0.81\" title=\"-0.045\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.19%); opacity: 0.82\" title=\"-0.082\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.27%); opacity: 0.82\" title=\"-0.099\">us</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.73%); opacity: 0.81\" title=\"-0.057\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.25%); opacity: 0.80\" title=\"0.012\">bit</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 86.58%); opacity: 0.84\" title=\"0.217\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.95%); opacity: 0.85\" title=\"0.255\">explanation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.98%); opacity: 0.84\" title=\"0.231\">here</span><span style=\"opacity: 0.80\">?   </span><span style=\"background-color: hsl(120, 100.00%, 85.81%); opacity: 0.85\" title=\"0.235\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.81%); opacity: 0.85\" title=\"0.235\">example</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 90.23%); opacity: 0.83\" title=\"0.138\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.58%); opacity: 0.84\" title=\"0.217\">religion</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.48%); opacity: 0.80\" title=\"0.020\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.27%); opacity: 0.81\" title=\"-0.049\">anti</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.085\">semitic</span><span style=\"opacity: 0.80\">,\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 93.03%); opacity: 0.82\" title=\"0.085\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.60%); opacity: 0.83\" title=\"0.172\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.04%); opacity: 0.84\" title=\"0.206\">aesthetic</span><span style=\"opacity: 0.80\">?</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(sample, text_clf.predict_proba)\n",
    "te.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "eafde9f2-8db8-4a42-a8e5-06003f54f2e9"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to trick the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bae60a77-1fc6-4800-826d-72cfca6562f1"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Never trust an algorithm blindly!\n",
    "- Cannot provide a good explanation for a black-box classifier which works on character level\n",
    "- Black-box classifiers which use features like “text length” (not directly related to tokens) can be also hard to approximate using the default bag-of-words/ngrams model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_proba_len(docs):\n",
    "    proba = [\n",
    "        [0, 1.0, 0.0, 0] if len(doc) % 2 else [1.0, 0, 0, 0]\n",
    "        for doc in docs\n",
    "    ]\n",
    "    return np.array(proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=comp.graphics\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.546</b>, score <b>0.183</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.255\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.072\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 82.10%); opacity: 0.86\" title=\"0.112\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.20%); opacity: 0.82\" title=\"0.034\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(120, 100.00%, 82.82%); opacity: 0.86\" title=\"0.106\">1993apr3</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 70.10%); opacity: 0.93\" title=\"0.234\">153552</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 78.52%); opacity: 0.88\" title=\"0.146\">4334</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(120, 100.00%, 94.26%); opacity: 0.81\" title=\"0.022\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 96.09%); opacity: 0.81\" title=\"-0.013\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 95.42%); opacity: 0.81\" title=\"0.016\">macalstr</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 81.10%); opacity: 0.87\" title=\"0.121\">edu</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(120, 100.00%, 86.68%); opacity: 0.84\" title=\"0.074\">acooper</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 96.43%); opacity: 0.81\" title=\"-0.011\">mac</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 96.09%); opacity: 0.81\" title=\"-0.013\">cc</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 95.42%); opacity: 0.81\" title=\"0.016\">macalstr</span><span style=\"opacity: 0.80\">.edu </span><span style=\"background-color: hsl(0, 100.00%, 82.28%); opacity: 0.86\" title=\"-0.111\">writes</span><span style=\"opacity: 0.80\">:\n",
       "|&gt; </span><span style=\"background-color: hsl(0, 100.00%, 88.77%); opacity: 0.83\" title=\"-0.058\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.00%); opacity: 0.81\" title=\"0.018\">article</span><span style=\"opacity: 0.80\"> &lt;</span><span style=\"background-color: hsl(120, 100.00%, 66.96%); opacity: 0.95\" title=\"0.270\">1pint5</span><span style=\"opacity: 0.80\">$</span><span style=\"background-color: hsl(120, 100.00%, 83.64%); opacity: 0.86\" title=\"0.099\">1l4</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 82.13%); opacity: 0.86\" title=\"-0.112\">fido</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 93.97%); opacity: 0.81\" title=\"0.024\">asd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 90.54%); opacity: 0.83\" title=\"0.045\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(120, 100.00%, 97.83%); opacity: 0.80\" title=\"0.005\">com</span><span style=\"opacity: 0.80\">&gt;, </span><span style=\"background-color: hsl(0, 100.00%, 86.79%); opacity: 0.84\" title=\"-0.073\">livesey</span><span style=\"opacity: 0.80\">@</span><span style=\"background-color: hsl(0, 100.00%, 85.88%); opacity: 0.85\" title=\"-0.080\">solntze</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 89.67%); opacity: 0.83\" title=\"-0.051\">wpd</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 91.02%); opacity: 0.82\" title=\"-0.042\">sgi</span><span style=\"opacity: 0.80\">.</span><span style=\"background-color: hsl(0, 100.00%, 84.06%); opacity: 0.85\" title=\"-0.095\">com</span><span style=\"opacity: 0.80\"> (</span><span style=\"background-color: hsl(0, 100.00%, 76.92%); opacity: 0.89\" title=\"-0.161\">jon</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.29%); opacity: 0.94\" title=\"-0.254\">livesey</span><span style=\"opacity: 0.80\">) </span><span style=\"background-color: hsl(120, 100.00%, 92.16%); opacity: 0.82\" title=\"0.035\">writes</span><span style=\"opacity: 0.80\">\n",
       "&gt;\n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 76.70%); opacity: 0.89\" title=\"0.164\">well</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 69.47%); opacity: 0.94\" title=\"0.241\">germany</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 69.77%); opacity: 0.93\" title=\"-0.237\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.67%); opacity: 0.87\" title=\"-0.125\">hardly</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.23%); opacity: 0.86\" title=\"-0.102\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.35%); opacity: 0.92\" title=\"0.209\">only</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.77%); opacity: 0.87\" title=\"0.124\">country</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.44%); opacity: 0.86\" title=\"-0.100\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.72%); opacity: 0.90\" title=\"0.174\">discriminate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.40%); opacity: 0.85\" title=\"-0.092\">against</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.04%); opacity: 0.87\" title=\"0.122\">the</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 72.40%); opacity: 0.92\" title=\"0.208\">jews</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 92.85%); opacity: 0.82\" title=\"0.030\">although</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.97%); opacity: 0.81\" title=\"0.013\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.54%); opacity: 0.80\" title=\"0.007\">has</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.02%); opacity: 0.90\" title=\"-0.171\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.82%); opacity: 0.82\" title=\"-0.030\">worst</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.94%); opacity: 0.84\" title=\"0.064\">reputation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.28%); opacity: 0.85\" title=\"0.093\">because</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.39%); opacity: 0.90\" title=\"0.177\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.44%); opacity: 0.87\" title=\"-0.127\">did</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.96%); opacity: 0.85\" title=\"-0.096\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.75%); opacity: 0.85\" title=\"-0.081\">best</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.40%); opacity: 0.91\" title=\"0.187\">job</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 79.73%); opacity: 0.88\" title=\"-0.134\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.33%); opacity: 0.91\" title=\"-0.188\">expressing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.99%); opacity: 0.84\" title=\"-0.071\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.11%); opacity: 0.80\" title=\"-0.005\">general</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.04%); opacity: 0.83\" title=\"-0.056\">european</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.93%); opacity: 0.90\" title=\"0.182\">dislike</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 74.93%); opacity: 0.90\" title=\"0.182\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.85%); opacity: 0.82\" title=\"0.030\">them</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 78.29%); opacity: 0.88\" title=\"0.148\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.61%); opacity: 0.89\" title=\"0.165\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.62%); opacity: 0.83\" title=\"-0.052\">not</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.04%); opacity: 0.93\" title=\"-0.223\">turn</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 68.77%); opacity: 0.94\" title=\"-0.249\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.53%); opacity: 0.81\" title=\"0.026\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.12%); opacity: 0.80\" title=\"0.008\">debate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.44%); opacity: 0.86\" title=\"-0.101\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.73%); opacity: 0.94\" title=\"-0.249\">antisemitism</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 88.75%); opacity: 0.83\" title=\"-0.058\">but</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.74%); opacity: 0.88\" title=\"0.144\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.16%); opacity: 0.85\" title=\"-0.094\">should</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.94%); opacity: 0.82\" title=\"0.042\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.87%); opacity: 0.84\" title=\"0.072\">point</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.42%); opacity: 0.94\" title=\"0.241\">out</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.07%); opacity: 0.88\" title=\"0.140\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 72.28%); opacity: 0.92\" title=\"-0.210\">luther</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 80.36%); opacity: 0.87\" title=\"0.128\">s</span><span style=\"opacity: 0.80\">\n",
       "&gt;  </span><span style=\"background-color: hsl(120, 100.00%, 74.91%); opacity: 0.90\" title=\"0.182\">antisemitism</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.90%); opacity: 0.80\" title=\"0.002\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.37%); opacity: 0.90\" title=\"0.177\">based</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 76.83%); opacity: 0.89\" title=\"-0.162\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.80%); opacity: 0.85\" title=\"0.081\">religious</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.50%); opacity: 0.83\" title=\"0.052\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 74.31%); opacity: 0.91\" title=\"-0.188\">while</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.96%); opacity: 0.81\" title=\"0.024\">hitler</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 97.67%); opacity: 0.80\" title=\"-0.006\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.46%); opacity: 0.92\" title=\"-0.219\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.69%); opacity: 0.87\" title=\"0.116\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.77%); opacity: 0.82\" title=\"0.037\">racial</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(120, 100.00%, 88.78%); opacity: 0.83\" title=\"0.058\">grounds</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 69.13%); opacity: 0.94\" title=\"0.245\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.85%); opacity: 0.85\" title=\"0.080\">wagnmer</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 83.49%); opacity: 0.86\" title=\"-0.100\">s</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.03%); opacity: 0.84\" title=\"-0.071\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.50%); opacity: 0.86\" title=\"-0.109\">aesthetic</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.11%); opacity: 0.84\" title=\"0.070\">grounds</span><span style=\"opacity: 0.80\">.  </span><span style=\"background-color: hsl(120, 100.00%, 84.08%); opacity: 0.85\" title=\"0.095\">just</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.97%); opacity: 0.83\" title=\"0.049\">blanketing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 81.28%); opacity: 0.87\" title=\"-0.120\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.96%); opacity: 0.86\" title=\"0.105\">whole</span><span style=\"opacity: 0.80\"> \n",
       "&gt; </span><span style=\"background-color: hsl(0, 100.00%, 66.91%); opacity: 0.95\" title=\"-0.270\">group</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.45%); opacity: 0.86\" title=\"-0.109\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.06%); opacity: 0.85\" title=\"-0.095\">poor</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 61.93%); opacity: 0.99\" title=\"-0.330\">analysis</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 93.01%); opacity: 0.82\" title=\"0.029\">even</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.50%); opacity: 0.81\" title=\"0.011\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.42%); opacity: 0.83\" title=\"0.053\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.91%); opacity: 0.87\" title=\"0.132\">all</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.59%); opacity: 0.86\" title=\"0.108\">are</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.16%); opacity: 0.86\" title=\"-0.112\">bigots</span><span style=\"opacity: 0.80\">.\n",
       "\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 89.65%); opacity: 0.83\" title=\"-0.051\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.25%); opacity: 0.81\" title=\"0.022\">find</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.70%); opacity: 0.84\" title=\"0.066\">these</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.03%); opacity: 0.84\" title=\"0.071\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.01%); opacity: 0.80\" title=\"0.005\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.11%); opacity: 0.82\" title=\"0.035\">intriguing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.14%); opacity: 0.87\" title=\"0.130\">remarks</span><span style=\"opacity: 0.80\">.   </span><span style=\"background-color: hsl(0, 100.00%, 88.67%); opacity: 0.83\" title=\"-0.058\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.41%); opacity: 0.90\" title=\"-0.177\">you</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.35%); opacity: 0.86\" title=\"0.101\">give</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.354\">us</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.98%); opacity: 0.86\" title=\"0.113\">a</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.73%); opacity: 0.92\" title=\"0.205\">bit</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 79.88%); opacity: 0.87\" title=\"-0.133\">more</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.19%); opacity: 0.84\" title=\"-0.070\">explanation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 75.49%); opacity: 0.90\" title=\"-0.176\">here</span><span style=\"opacity: 0.80\">?   </span><span style=\"background-color: hsl(0, 100.00%, 66.91%); opacity: 0.95\" title=\"-0.270\">for</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.93%); opacity: 0.88\" title=\"-0.142\">example</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 80.75%); opacity: 0.87\" title=\"-0.125\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.83%); opacity: 0.86\" title=\"-0.106\">religion</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.82%); opacity: 0.88\" title=\"0.133\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.13%); opacity: 0.82\" title=\"-0.041\">anti</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(0, 100.00%, 72.71%); opacity: 0.92\" title=\"-0.205\">semitic</span><span style=\"opacity: 0.80\">,\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 71.75%); opacity: 0.92\" title=\"-0.216\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.95%); opacity: 0.88\" title=\"-0.142\">which</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.13%); opacity: 0.80\" title=\"0.002\">aesthetic</span><span style=\"opacity: 0.80\">?</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te2 = TextExplainer().fit(sample, predict_proba_len)\n",
    "te2.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can detect this failure by __looking at__ metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- ‘score’ is an accuracy score weighted by cosine distance between generated sample and the original document (i.e. texts which are closer to the example are more important). Accuracy shows how good are ‘top 1’ predictions.\n",
    "- ‘mean_KL_divergence’ is a mean Kullback–Leibler divergence for all target classes; it is also weighted by distance. KL divergence shows how well are probabilities approximated; 0.0 means a perfect match.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_KL_divergence': 0.72973696077940187, 'score': 0.48996566001842468}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te2.metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Luckily it's possible to fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If we suspect that the fact document length is even or odd is important, it is possible to customize TextExplainer to check this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class DocLength(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return [[len(doc) % 2, not len(doc) % 2] for doc in X]\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return ['is_odd', 'is_even']\n",
    "\n",
    "vec = make_union(DocLength(), CountVectorizer(ngram_range=(1,2)))\n",
    "te3 = TextExplainer(vec=vec).fit(sample, predict_proba_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_KL_divergence': 0.011840784438819842, 'score': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=alt.atheism\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.988</b>, score <b>-4.448</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.419\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        doclength__is_even\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        countvectorizer: Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <b>countvectorizer:</b> <span style=\"opacity: 0.80\">in article &lt;1993apr3.153552.4334@mac.cc.macalstr.edu&gt;, acooper@mac.cc.macalstr.edu writes:\n",
       "|&gt; in article &lt;1pint5$1l4@fido.asd.sgi.com&gt;, livesey@solntze.wpd.sgi.com (jon livesey) writes\n",
       "&gt;\n",
       "&gt; well, germany was hardly the only country to discriminate against the \n",
       "&gt; jews, although it has the worst reputation because it did the best job \n",
       "&gt; of expressing a general european dislike of them.  this should not turn \n",
       "&gt; into a debate on antisemitism, but you should also point out that luther&#x27;s\n",
       "&gt;  antisemitism was based on religious grounds, while hitler&#x27;s was on racial \n",
       "&gt; grounds, and wagnmer&#x27;s on aesthetic grounds.  just blanketing the whole \n",
       "&gt; group is poor analysis, even if they all are bigots.\n",
       "\n",
       "i find these to be intriguing remarks.   could you give us a bit\n",
       "more </span><span style=\"background-color: hsl(0, 100.00%, 95.25%); opacity: 0.81\" title=\"-0.001\">explanation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.016\">here</span><span style=\"opacity: 0.80\">?   for example, which religion is anti-semitic,\n",
       "and which aesthetic?</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\\n       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\\n       n_jobs=1, penalty='elasticnet', power_t=0.5,\\n       random_state=<mtrand.RandomState object at 0x7f684037f510>,\\n       shuffle=True, tol=0.001, verbose=0, warm_start=False)\", description=None, error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target='alt.atheism', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='doclength__is_even', weight=4.4186466180777462, std=None, value=1.0), FeatureWeight(feature='countvectorizer__here', weight=0.015677176176287444, std=None, value=1.0), FeatureWeight(feature='<BIAS>', weight=0.014359554391543176, std=None, value=1.0)], neg=[FeatureWeight(feature='countvectorizer__explanation', weight=-0.00074740982228901508, std=None, value=1.0)], pos_remaining=0, neg_remaining=0), proba=0.98843267179710925, score=-4.4479359388232877, weighted_spans=WeightedSpans(docs_weighted_spans=[DocWeightedSpans(document=\"in article <1993apr3.153552.4334@mac.cc.macalstr.edu>, acooper@mac.cc.macalstr.edu writes:\\n|> in article <1pint5$1l4@fido.asd.sgi.com>, livesey@solntze.wpd.sgi.com (jon livesey) writes\\n>\\n> well, germany was hardly the only country to discriminate against the \\n> jews, although it has the worst reputation because it did the best job \\n> of expressing a general european dislike of them.  this should not turn \\n> into a debate on antisemitism, but you should also point out that luther's\\n>  antisemitism was based on religious grounds, while hitler's was on racial \\n> grounds, and wagnmer's on aesthetic grounds.  just blanketing the whole \\n> group is poor analysis, even if they all are bigots.\\n\\ni find these to be intriguing remarks.   could you give us a bit\\nmore explanation here?   for example, which religion is anti-semitic,\\nand which aesthetic?\", spans=[('explanation', [(765, 776)], -0.00074740982228901508), ('here', [(777, 781)], 0.015677176176287444)], preserve_density=False, vec_name='countvectorizer')], other=FeatureWeights(pos=[FeatureWeight(feature='doclength__is_even', weight=4.4186466180777462, std=None, value=1.0), FeatureWeight(feature=<FormattedFeatureName 'countvectorizer: Highlighted in text (sum)'>, weight=0.014929766353998428, std=None, value=None), FeatureWeight(feature='<BIAS>', weight=0.014359554391543176, std=None, value=1.0)], neg=[], pos_remaining=0, neg_remaining=0)))], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(te3.metrics_)\n",
    "te3.explain_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "What’s bad about this kind of failure (wrong assumption about the black-box pipeline) is that it could be impossible to detect the failure by looking at the scores. Scores could be high because generated dataset is not diverse enough, not because our approximation is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The takeaway is that it is important to understand the “lenses” you’re looking through when using LIME to explain a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tl;dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Inspect your models not only by looking at validation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- LIME can help you to get some understanding of your model (and eli5 makes it easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It's important to understand the “lenses” you’re looking through when using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Never trust an alogrithm blindly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to find me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"img/www.png\" alt=\"website\" style=\"width: 50px;float: left;\"/> <p>www.depends-on-the-definition.com</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"img/github.png\" alt=\"website\" style=\"width: 50px;float: left;\"/><p>www.github.com/tsterbak</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"img/twitter.png\" alt=\"website\" style=\"width: 50px;float: left;\"/> <p>@tobias_sterbak</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "02f6fc2b-a2bb-4b5c-8f48-78cffde30fbf",
    "theme": {
     "02f6fc2b-a2bb-4b5c-8f48-78cffde30fbf": {
      "id": "02f6fc2b-a2bb-4b5c-8f48-78cffde30fbf",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     },
     "8fd18290-d9b6-4b93-952c-cab71c13f9a9": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "8fd18290-d9b6-4b93-952c-cab71c13f9a9",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
